{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O PROBLEMA\n",
    "\n",
    "Imagine agora que você foi contratado(a) como Expert em Data Analytics por um grande hospital para entender como foi o comportamento da população na época da pandemia da COVID-19 e quais indicadores seriam importantes para o planejamento, caso haja um novo surto da doença.\n",
    "\n",
    "Apesar de ser contratado(a) agora, a sua área observou que a utilização do estudo do PNAD-COVID 19 do IBGE seria uma ótima base para termos boas respostas ao problema proposto, pois são dados confiáveis.Porém, não será necessário utilizar todas as perguntas realizadas na pesquisa para enxergar todas as oportunidades ali postas.\n",
    "\n",
    "É sempre bom ressaltar que há dados triviais que precisam estar no projeto, pois auxiliam muito na análise dos dados:\n",
    "\n",
    "## PNAD-COVID-19 do IBGE\n",
    "\n",
    "O Head de Dados pediu para que você entrasse na base de dados do PNAD-COVID-19 do IBGE e organizasse esta base para análise, utilizando Banco de Dados em Nuvem e trazendo as seguintes características:\n",
    "\n",
    "- a. Utilização de no máximo 20 questionamentos realizados na pesquisa;\n",
    "- b. Utilizar 3 meses para construção da solução;\n",
    "- c. Caracterização dos sintomas clínicos da população;\n",
    "- d. Comportamento da população na época da COVID-19;\n",
    "- e. Características econômicas da Sociedade;\n",
    "\n",
    "Seu objetivo será trazer uma breve análise dessas informações, como foi a organização do banco, as perguntas selecionadas para a resposta do problema e quais seriam as principais ações que o hospital deverá tomar em caso de um novo surto de COVID-19.\n",
    "\n",
    "- Dica: Leiam com atenção a base de dados e toda a documentação que o site o PNAD – Covid19 traz, principalmente os dicionários, que ajudam e muito no entendimento da Base de Dados.\n",
    "- Dica 2: Utilizem o que já foi ensinado e consolidado nas outras fases para apresentar a resolução do projeto.\n",
    "\n",
    "Lembre-se de que você poderá apresentar o desenvolvimento do seu projeto durante as lives com docentes. Essa é uma boa oportunidade para discutir sobre as dificuldades encontradas e pegar dicas valiosas com especialistas e colegas de turma.\n",
    "\n",
    "Link para a base: https://www.ibge.gov.br/estatisticas/investigacoes-experimentais/estatisticas-experimentais/27946-divulgacao-semanal-pnadcovid1?t=downloads&utm_source=covid19&utm_medium=hotsite&utm_campaign=covid_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectando ao MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysql_connection(host, user, passwd, database=None):\n",
    "    engine = create_engine(f'mysql+pymysql://{user}:{passwd}@{host}/{database}')\n",
    "    return engine.connect()\n",
    "\n",
    "mysql = mysql_connection('127.0.0.1', 'root', 'admin', 'pnad_covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2020, 9, 1), 'Espírito Santo', 'Urbana', 84, 'Homem', 'Parda', 'Fundamental incompleto', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não', 'Não', '1045', '600', 'Não', 'Próprio - já pago ', 'Não aplicável', 'Não aplicável', 'Não', 'Não Aplicável', 'Sim')\n",
      "(datetime.date(2020, 9, 1), 'Não identificado', 'Urbana', 49, 'Homem', 'Branca', 'Superior completo', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Artesão, costureiro e sapateiro', '801 - 1.600', '800', 'Não', 'Não', 'Não', 'Não', 'Próprio - já pago ', 'Não aplicável', 'Não aplicável', 'Não', 'Não Aplicável', 'Sim')\n",
      "(datetime.date(2020, 7, 1), 'Mato Grosso', 'Urbana', 50, 'Mulher', 'Parda', 'Superior completo', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não', 'Não', 'Não', '1200', 'Não', 'Próprio - já pago ', 'Não aplicável', 'Não aplicável', 'Não', 'Não Aplicável', 'Sim')\n",
      "(datetime.date(2020, 7, 1), 'Não identificado', 'Urbana', 41, 'Mulher', 'Parda', 'Superior completo', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Balconista, vendedor de loja', '1.601 - 3.000', 'Não', 'Não', 'Não', 'Não', 'Não', 'Cedido por familiar ', 'Não aplicável', 'Não aplicável', 'Não', 'Não Aplicável', 'Não Aplicável')\n",
      "(datetime.date(2020, 7, 1), 'Santa Catarina', 'Rural', 25, 'Mulher', 'Parda', 'Fundamental incompleto', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não aplicável', 'Não', 'Não', 'Não', '1200', 'Não', 'Próprio - já pago ', 'Não aplicável', 'Não aplicável', 'Não', 'Não Aplicável', 'Não Aplicável')\n"
     ]
    }
   ],
   "source": [
    "'''statement = text('SELECT * FROM pnad_covid_view LIMIT 5')\n",
    "response = mysql.execute(statement)\n",
    "for row in response:\n",
    "        print(row)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando sessão Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''os.environ['SPARK_HOME'] = '/opt/spark/'\n",
    "findspark.init()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/23 21:07:06 WARN Utils: Your hostname, platero-Lenovo-IdeaPad-S145-15IWL resolves to a loopback address: 127.0.1.1; using 192.168.15.109 instead (on interface wlp2s0)\n",
      "23/10/23 21:07:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/23 21:07:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "'''spark = SparkSession.builder.master('local[*]').getOrCreate()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.15.109:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbedfdb1df0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spark'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_05 = spark.read.csv('dados/dados_importados/PNAD_COVID_052020.csv', sep=',', inferSchema=True, header=True)\\ndf_06 = spark.read.csv('dados/dados_importados/PNAD_COVID_062020.csv', sep=',', inferSchema=True, header=True)\\ndf_07 = spark.read.csv('dados/dados_importados/PNAD_COVID_072020.csv', sep=',', inferSchema=True, header=True)\\ndf_08 = spark.read.csv('dados/dados_importados/PNAD_COVID_082020.csv', sep=',', inferSchema=True, header=True)\\ndf_09 = spark.read.csv('dados/dados_importados/PNAD_COVID_092020.csv', sep=',', inferSchema=True, header=True)\\ndf_10 = spark.read.csv('dados/dados_importados/PNAD_COVID_102020.csv', sep=',', inferSchema=True, header=True)\\ndf_11 = spark.read.csv('dados/dados_importados/PNAD_COVID_112020.csv', sep=',', inferSchema=True, header=True)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_05 = spark.read.csv('dados/dados_importados/PNAD_COVID_052020.csv', sep=',', inferSchema=True, header=True)\n",
    "df_06 = spark.read.csv('dados/dados_importados/PNAD_COVID_062020.csv', sep=',', inferSchema=True, header=True)\n",
    "df_07 = spark.read.csv('dados/dados_importados/PNAD_COVID_072020.csv', sep=',', inferSchema=True, header=True)\n",
    "df_08 = spark.read.csv('dados/dados_importados/PNAD_COVID_082020.csv', sep=',', inferSchema=True, header=True)\n",
    "df_09 = spark.read.csv('dados/dados_importados/PNAD_COVID_092020.csv', sep=',', inferSchema=True, header=True)\n",
    "df_10 = spark.read.csv('dados/dados_importados/PNAD_COVID_102020.csv', sep=',', inferSchema=True, header=True)\n",
    "df_11 = spark.read.csv('dados/dados_importados/PNAD_COVID_112020.csv', sep=',', inferSchema=True, header=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pyspark.sql.functions import lit\\n\\ndef add_missing_cols(df):\\n    cols = df_11.columns\\n    new_cols = []\\n\\n    for col_name in cols: #selecionando colunas faltantes\\n        if col_name not in df.columns:\\n            new_cols.append(col_name)\\n\\n    for new_col_name in new_cols: #adicionando colunas faltantes\\n        df = df.withColumn(new_col_name, lit(None))\\n\\n    return df.select(cols) #organizando colunas\\n\\ndf_05 = add_missing_cols(df_05)\\ndf_06 = add_missing_cols(df_06)\\ndf_07 = add_missing_cols(df_07)\\ndf_08 = add_missing_cols(df_08)\\ndf_09 = add_missing_cols(df_09)\\ndf_10 = add_missing_cols(df_10)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#padronizando número de colunas\n",
    "'''from pyspark.sql.functions import lit\n",
    "\n",
    "def add_missing_cols(df):\n",
    "    cols = df_11.columns\n",
    "    new_cols = []\n",
    "\n",
    "    for col_name in cols: #selecionando colunas faltantes\n",
    "        if col_name not in df.columns:\n",
    "            new_cols.append(col_name)\n",
    "\n",
    "    for new_col_name in new_cols: #adicionando colunas faltantes\n",
    "        df = df.withColumn(new_col_name, lit(None))\n",
    "\n",
    "    return df.select(cols) #organizando colunas\n",
    "\n",
    "df_05 = add_missing_cols(df_05)\n",
    "df_06 = add_missing_cols(df_06)\n",
    "df_07 = add_missing_cols(df_07)\n",
    "df_08 = add_missing_cols(df_08)\n",
    "df_09 = add_missing_cols(df_09)\n",
    "df_10 = add_missing_cols(df_10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf = df_05.union(df_06)\\ndf = df.union(df_07)\\ndf = df.union(df_08)\\ndf = df.union(df_09)\\ndf = df.union(df_10)\\ndf = df.union(df_11)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenando DataFrames\n",
    "'''\n",
    "df = df_05.union(df_06)\n",
    "df = df.union(df_07)\n",
    "df = df.union(df_08)\n",
    "df = df.union(df_09)\n",
    "df = df.union(df_10)\n",
    "df = df.union(df_11)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df.show(5)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df.show(5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df.select('C007C').where(df['V1013'] == '06').show(5)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df.select('C007C').where(df['V1013'] == '06').show(5)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando DataFrame para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df.coalesce(1).write.csv(\\n    path='dados/dados_exportados',\\n    mode='overwrite',\\n    sep=',',\\n    header=True\\n)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exportando arquivo csv único\n",
    "'''df.coalesce(1).write.csv(\n",
    "    path='dados/dados_exportados',\n",
    "    mode='overwrite',\n",
    "    sep=',',\n",
    "    header=True\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df = spark.read.csv('dados/dados_exportados/PNAD_COVID.csv', sep=',', inferSchema=True, header=True)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df = spark.read.csv('dados/dados_exportados/PNAD_COVID.csv', sep=',', inferSchema=True, header=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df.show(5)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df.show(5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df.count()'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df.count()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n_splits = 5\\nn_rows = df.count() // n_splits\\ncopy_df = df\\n\\nfor i in range(1, n_splits + 1):\\n    temp_df = copy_df.limit(n_rows)\\n    copy_df = copy_df.subtract(temp_df) #subtraindo conteúdo seguimentado\\n    \\n    #exportando seguimento\\n    temp_df.coalesce(1).write.csv(\\n    path=f'dados/dados_exportados/dados_seguimentados/seguimento_{i}',\\n    mode='overwrite',\\n    sep=',',\\n    header=True\\n    )\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exportando seguimentos do DataFrame\n",
    "'''n_splits = 5\n",
    "n_rows = df.count() // n_splits\n",
    "copy_df = df\n",
    "\n",
    "for i in range(1, n_splits + 1):\n",
    "    temp_df = copy_df.limit(n_rows)\n",
    "    copy_df = copy_df.subtract(temp_df) #subtraindo conteúdo seguimentado\n",
    "    \n",
    "    #exportando seguimento\n",
    "    temp_df.coalesce(1).write.csv(\n",
    "    path=f'dados/dados_exportados/dados_seguimentados/seguimento_{i}',\n",
    "    mode='overwrite',\n",
    "    sep=',',\n",
    "    header=True\n",
    "    )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_1 = spark.read.csv('dados/dados_exportados/dados_seguimentados/seguimento_1/*.csv', sep=',', inferSchema=True, header=True)\\ndf_2 = spark.read.csv('dados/dados_exportados/dados_seguimentados/seguimento_2/*.csv', sep=',', inferSchema=True, header=True)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_1 = spark.read.csv('dados/dados_exportados/dados_seguimentados/seguimento_1/*.csv', sep=',', inferSchema=True, header=True)\n",
    "df_2 = spark.read.csv('dados/dados_exportados/dados_seguimentados/seguimento_2/*.csv', sep=',', inferSchema=True, header=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_1.show(5)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_1.show(5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_2.show(5)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_2.show(5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df.createOrReplaceTempView('view')\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df.createOrReplaceTempView('view')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"spark.sql('SELECT ANO, V1023, CAPITAL FROM view WHERE V1013 = 05 LIMIT 5').toPandas()\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''spark.sql('SELECT ANO, V1023, CAPITAL FROM view WHERE V1013 = 05 LIMIT 5').toPandas()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando dados para o MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_1.csv')\\ndf.to_sql('dados_covid', mysql, if_exists='append', index=False)\\nmysql.execute(text('COMMIT'))\\n\\ndf = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_2.csv')\\ndf.to_sql('dados_covid', mysql, if_exists='append', index=False)\\nmysql.execute(text('COMMIT'))\\n\\ndf = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_3.csv')\\ndf.to_sql('dados_covid', mysql, if_exists='append', index=False)\\nmysql.execute(text('COMMIT'))\\n\\ndf = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_4.csv')\\ndf.to_sql('dados_covid', mysql, if_exists='append', index=False)\\nmysql.execute(text('COMMIT'))\\n\\ndf = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_5.csv')\\ndf.to_sql('dados_covid', mysql, if_exists='append', index=False)\\nmysql.execute(text('COMMIT'))\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_1.csv')\n",
    "df.to_sql('dados_covid', mysql, if_exists='append', index=False)\n",
    "mysql.execute(text('COMMIT'))\n",
    "\n",
    "df = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_2.csv')\n",
    "df.to_sql('dados_covid', mysql, if_exists='append', index=False)\n",
    "mysql.execute(text('COMMIT'))\n",
    "\n",
    "df = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_3.csv')\n",
    "df.to_sql('dados_covid', mysql, if_exists='append', index=False)\n",
    "mysql.execute(text('COMMIT'))\n",
    "\n",
    "df = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_4.csv')\n",
    "df.to_sql('dados_covid', mysql, if_exists='append', index=False)\n",
    "mysql.execute(text('COMMIT'))\n",
    "\n",
    "df = pd.read_csv('/home/platero/postech_techchallenge_fase_3/dados/dados_exportados/dados_seguimentados/seguimento_5.csv')\n",
    "df.to_sql('dados_covid', mysql, if_exists='append', index=False)\n",
    "mysql.execute(text('COMMIT'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando dados do MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = text('SELECT * FROM pnad_covid_view WHERE data >= 2020-09-01 LIMIT 1000')\n",
    "df = pd.read_sql_query(statement, con=mysql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['data', 'uf', 'situacao_domicilio', 'idade', 'sexo', 'cor_raca',\n",
       "       'escolaridade', 'questao_estabelecimento_saude',\n",
       "       'questao_permaneceu_casa', 'questao_remedio_conta_propria',\n",
       "       'questao_remedio_orientacao_medica', 'questao_hospital_SUS',\n",
       "       'questao_hospital_privado', 'questao_internacao',\n",
       "       'questao_internacao_ajuda_respirar', 'questao_motivo_afastamento',\n",
       "       'questao_tempo_afastado_trab', 'questao_tipo_trabalho_realizado',\n",
       "       'faixa_rendimento', 'rendimento_aposentadoria_pensao',\n",
       "       'rendimento_bolsa_familia', 'rendimento_beneficios',\n",
       "       'auxlio_emergencia_covid', 'seguro_desemprego', 'tipo_domicilio',\n",
       "       'valor_pago_domicilio', 'sintoma_covid', 'teste_covid', 'tipo_teste',\n",
       "       'fator_risco_covid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
